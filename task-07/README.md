# Rich Scraper
### This is the only task which i took a week ig...I sat for hours in front of my computer and laptop but wasnt getting how it is working and how the scrapper is scrapping infos from the [website](https://www.forbes.com/real-time-billionaires/) , it was a prerry hard task in the first ....ofc when you get used to it you'll get to know the working of it, thats how i got the working done.
### I have made 3 folders here in this folder and i have added all the attempts and failure  ihave come across 
- First attempt was the first time i started to scrap infos from the website and that was the biggest failure cause i thought to watch some youtube [tutorial] which actually helped me learning  golang(i learned golang on doing this task).The first attempt i made the go file and thought it might work but wasnt .....GOCOLLY was the framework i used to complete the [first_attempt](https://github.com/rakshith6404/amfoss-stage0/tree/main/task-07/attempt_1_failure) . In this attempt the main was working fine without any errors i didnt get any errors(err function helped me in this) while creating the file named data.csv but was actually but wsa actually getting a plain csv file which didnt have any datas in it.I have attached that [here](https://github.com/rakshith6404/amfoss-stage0/blob/main/task-07/attempt_1_failure/data.csv).
- [Second attempt](https://github.com/rakshith6404/amfoss-stage0/tree/main/task-07/attempt_2_failure) the same thing happened but i noticed that the the Question which was given indicated only to get the net_worth,age,source and country/territory.But when i assigned a struct function which i used to append all the datas into the variable later , that too didnt happen . I was getting the blank CSV file i was getting in the first_attempt.This time i printed the OnRequest function to get the link the golang web scrapper have visited and also i gave all the variables inside the stuct function to be a string cause i tried it with int type and thought to convert the same to int using atoi method , which didnt end up pretty well ; and finally have given a loop in which it will scrap the first 10 people list, that too didnt end up well . I thought to quit this one right away cause it was literally 3-4 days of sleepless nigths.I started to do the [flutter](https://github.com/rakshith6404/amfoss-stage0/tree/main/task-06) which i completed in 3 days.
- [Third attempt](https://github.com/rakshith6404/amfoss-stage0/tree/main/task-07/working(yeyeyhh)) literally went up well cause i didnt use GOCOLLY , instead used GEZIYOR ðŸ˜ŽðŸ˜Ž.I found that most of the people used GOCOLLY to webscrap and thats the only reason i went with it .....I didnt wanted to give up hope for this task so i installed the modules needed for GEZIYOR(which i heard to be a powerful and fast web-scrapping framework) and that literally worked a lot.This was really easy then i literally thought it would be . I literally lost hope when this script didnt end up well,the same thing happened (the csv file was empty) then the quote came to my mind,EVER TRIED EVER FAILED NO MATTER TRY AGAIN FAIL AGAIN FAIL BETTER, and this was the motivation i got and started to work on this task a bit more having more concentration and focussing on what i made a mistake in .I literally (i) didnt add a loop in the first case and (ii) used atoi to convert the strings to integer and also the important thing was i didnt ```\\/```  to country/territory (country```\\/```territory) and there it was **The [data](https://github.com/rakshith6404/amfoss-stage0/blob/main/task-07/working(yeyeyhh)/data.csv) which is needed for the task**.....I have printed only the needed data and also the needed data which is asked in the question.
## References i went through:
- [gocolly](http://go-colly.org/) and [github_page](https://github.com/gocolly/colly)
- [geziyor](https://github.com/geziyor/geziyor)
- [Tutorial](https://www.youtube.com/playlist?list=PLsyeobzWxl7pJ9Gy1iHRKjUTE5xPhJ18b) 

### This was the easiest task i would say if i would have used GEZIYOR , but i used gocolly and ofc i didnt waste up the days i have being through cause i literally learned many things in that journey.
#### I literally learned golang while doing this task .:lol.
##### EVER TRIED,EVER FAILED,NO MATTER TRY AGAIN,FAIL AGAIN , FAIL BETTER .ðŸ˜ŽðŸ˜Ž
